name: Event Data Deploy

# Triggered when a PR targeting main contains changes to event data files.
# Applies only to PRs from event/ (add-event) and event-edit/ (edit-event) branches.
#
# Jobs:
#   1. lint-yaml      – structural validation of the changed YAML file
#   2. security-check – injection scan, link protocol validation, QA-camp detection
#   3. deploy-qa      – build with QA secrets + SCP upload to QA
#   4. deploy-qa-node – build with QA secrets + SCP upload to QA Node
#   5. deploy-prod    – build with production secrets + FTP upload to production
#                       (skipped when the changed file belongs to a QA camp)
#   (3, 4, and 5 run in parallel after 2 passes)

permissions:
  contents: read

on:
  pull_request:
    branches:
      - main
    paths:
      - 'source/data/**.yaml'

jobs:
  lint-yaml:
    name: Lint event YAML
    runs-on: ubuntu-latest
    # Only run for PRs opened by the add-event or edit-event API flows.
    # Downstream jobs inherit this gate via their `needs:` chain.
    if: |
      startsWith(github.head_ref, 'event/') ||
      startsWith(github.head_ref, 'event-edit/')

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Detect changed event YAML file
        id: changed
        run: |
          git fetch origin main
          CHANGED=$(git diff --name-only origin/main...HEAD \
            | grep '^source/data/' | grep '\.yaml$' | grep -v 'camps\.yaml' | head -1)
          if [ -z "$CHANGED" ]; then
            echo "No event YAML file changed — nothing to validate"
            exit 1
          fi
          echo "yaml_file=$CHANGED" >> $GITHUB_OUTPUT
          echo "Detected changed file: $CHANGED"

      - name: Lint YAML
        run: node source/scripts/lint-yaml.js "${{ steps.changed.outputs.yaml_file }}"

  security-check:
    name: Security scan
    runs-on: ubuntu-latest
    needs: lint-yaml
    outputs:
      is_qa: ${{ steps.qa-check.outputs.is_qa }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Detect changed event YAML file
        id: changed
        run: |
          git fetch origin main
          CHANGED=$(git diff --name-only origin/main...HEAD \
            | grep '^source/data/' | grep '\.yaml$' | grep -v 'camps\.yaml' | head -1)
          echo "yaml_file=$CHANGED" >> $GITHUB_OUTPUT

      - name: Security scan
        run: node source/scripts/check-yaml-security.js "${{ steps.changed.outputs.yaml_file }}"

      - name: Check if changed file belongs to a QA camp
        id: qa-check
        run: |
          BASENAME=$(basename "${{ steps.changed.outputs.yaml_file }}")
          IS_QA=$(node -e "
            const fs = require('fs');
            const yaml = require('js-yaml');
            const camps = yaml.load(fs.readFileSync('source/data/camps.yaml','utf8'));
            const match = camps.camps.find(c => c.file === '$BASENAME');
            console.log(match && match.qa === true ? 'true' : 'false');
          ")
          echo "is_qa=$IS_QA" >> $GITHUB_OUTPUT
          echo "File $BASENAME is QA camp: $IS_QA"

  # Build with QA secrets and deploy event data pages to QA via SCP.
  deploy-qa:
    name: Build & deploy to QA
    runs-on: ubuntu-latest
    needs: security-check
    environment: qa

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build site
        run: npm run build
        env:
          API_URL: ${{ secrets.API_URL }}
          SITE_URL: ${{ secrets.SITE_URL }}
          BUILD_ENV: qa

      # Stage only event-data-derived files for upload.
      - name: Stage event data pages
        run: |
          mkdir -p staging
          for FILE in schema.html idag.html dagens-schema.html events.json schema.rss; do
            if [ -f "public/$FILE" ]; then
              cp "public/$FILE" "staging/$FILE"
              echo "Staged: $FILE"
            fi
          done
          if [ -d "public/schema" ]; then
            find public/schema -name 'index.html' | while read -r PAGE; do
              REL="${PAGE#public/}"
              mkdir -p "staging/$(dirname "$REL")"
              cp "$PAGE" "staging/$REL"
              echo "Staged: $REL"
            done
          fi

      - name: Upload event data pages via SCP
        uses: appleboy/scp-action@v1
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          port: ${{ secrets.SERVER_SSH_PORT }}
          source: staging/*
          target: ${{ secrets.DEPLOY_DIR }}/public_html
          strip_components: 1

  # Build with QA secrets and deploy event data pages to QA Node via SCP.
  deploy-qa-node:
    name: Build & deploy to QA Node
    runs-on: ubuntu-latest
    needs: security-check
    environment: qanode

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build site
        run: npm run build
        env:
          API_URL: ${{ secrets.API_URL }}
          SITE_URL: ${{ secrets.SITE_URL }}
          BUILD_ENV: qa

      # Stage only event-data-derived files for upload.
      - name: Stage event data pages
        run: |
          mkdir -p staging
          for FILE in schema.html idag.html dagens-schema.html events.json schema.rss; do
            if [ -f "public/$FILE" ]; then
              cp "public/$FILE" "staging/$FILE"
              echo "Staged: $FILE"
            fi
          done
          if [ -d "public/schema" ]; then
            find public/schema -name 'index.html' | while read -r PAGE; do
              REL="${PAGE#public/}"
              mkdir -p "staging/$(dirname "$REL")"
              cp "$PAGE" "staging/$REL"
              echo "Staged: $REL"
            done
          fi

      - name: Upload event data pages via SCP
        uses: appleboy/scp-action@v1
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          port: ${{ secrets.SERVER_SSH_PORT }}
          source: staging/*
          target: ${{ secrets.DEPLOY_DIR }}/public_html
          strip_components: 1

  # Build with production secrets and deploy event data pages to production.
  # Skipped when the changed file belongs to a QA camp — prevents overwriting
  # production schedule pages with an empty build.
  deploy-prod:
    name: Build & deploy to Production
    runs-on: ubuntu-latest
    needs: security-check
    if: needs.security-check.outputs.is_qa != 'true'
    environment: production

    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build site
        run: npm run build
        env:
          API_URL: ${{ secrets.API_URL }}
          SITE_URL: ${{ secrets.SITE_URL }}
          BUILD_ENV: production

      - name: Validate FTP_TARGET_DIR format
        run: |
          if [[ "${{ secrets.FTP_TARGET_DIR }}" != */ ]]; then
            echo "Error: FTP_TARGET_DIR must end with a '/'"
            exit 1
          fi
        shell: bash

      - name: Upload schema pages via FTP
        env:
          FTP_HOST: ${{ secrets.FTP_HOST }}
          FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
          FTP_TARGET_DIR: ${{ secrets.FTP_TARGET_DIR }}
        run: |
          for FILE in schema.html idag.html dagens-schema.html events.json schema.rss; do
            curl --ftp-create-dirs \
                 --upload-file "public/$FILE" \
                 --user "$FTP_USERNAME:$FTP_PASSWORD" \
                 "ftp://$FTP_HOST${FTP_TARGET_DIR}$FILE"
            echo "Uploaded: $FILE"
          done
          # Upload per-event detail pages
          if [ -d "public/schema" ]; then
            find public/schema -name 'index.html' | while read -r PAGE; do
              REL="${PAGE#public/}"
              curl --ftp-create-dirs \
                   --upload-file "$PAGE" \
                   --user "$FTP_USERNAME:$FTP_PASSWORD" \
                   "ftp://$FTP_HOST${FTP_TARGET_DIR}$REL"
              echo "Uploaded: $REL"
            done
          fi
